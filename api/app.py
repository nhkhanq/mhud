from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import joblib, pandas as pd, os, ast
from openai import OpenAI
from textwrap import dedent


# === 0. Ghi log ===
# --- th√™m cu·ªëi c·ª•m import ---
import uuid, datetime, pathlib

# --- kh·ªüi t·∫°o th∆∞ m·ª•c log ---
LOG_DIR = pathlib.Path("logs")
LOG_DIR.mkdir(exist_ok=True)

def write_log(line: str):
    """Ghi m·ªôt d√≤ng (k√®m timestamp) v√†o file log phi√™n hi·ªán t·∫°i."""
    log_name = getattr(app, "log_name", "default_session.txt")
    ts = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with (LOG_DIR / log_name).open("a", encoding="utf-8") as f:
        f.write(f"[{ts}] {line}\n")


# === 1. C·∫•u h√¨nh GPT-4o-mini ===
client = OpenAI(
    api_key="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"
)

# === 2. Load m√¥ h√¨nh ML ===
model_dir = os.path.join(os.getcwd(), "models")
model = joblib.load(os.path.join(model_dir, "best_rf_model.pkl"))
label_encoders = joblib.load(os.path.join(model_dir, "label_encoders.pkl"))
selected_features = joblib.load(os.path.join(model_dir, "selected_features.pkl"))

# --- 2.1 Ch·ªâ gi·ªØ encoder cho 6 c·ªôt ch·ªØ ---
NEED_ENCODE = [
    "Gender",
    "family_history_with_overweight",
    "FAVC",
    "SCC",
    "SMOKE",
    "MTRANS",
]
label_encoders = {k: v for k, v in label_encoders.items() if k in NEED_ENCODE}

# --- 2.2 C√°c c·ªôt s·ªë (kh√¥ng encode) ---
NUMERIC_COLS = [
    "Age", "Height", "Weight",
    "FCVC", "NCP", "TUE", "FAF",
    "CH2O", "CAEC", "CALC",
]

# === 3. Flask App ===
app = Flask(__name__)
CORS(app)

# === 4. Tr∆∞·ªùng th√¥ng tin c·∫ßn cho ML ===
required_fields = [
    "Gender", "Age", "Height", "Weight", "family_history_with_overweight",
    "FAVC", "FCVC", "NCP", "CAEC", "SMOKE", "CH2O", "SCC", "FAF",
    "TUE", "CALC", "MTRANS"
]

# === 5. System Prompt c·ªët l√µi (SYSTEM_CORE) ‚Äì phi√™n b·∫£n ƒë√£ ƒë∆∞·ª£c tinh ch·ªânh cho t·ª± nhi√™n ===
SYSTEM_CORE = {
    "role": "system",
    "content": (
        "üë©‚Äç‚öïÔ∏è B·∫°n l√† **B√°c sƒ© Dinh d∆∞·ª°ng AI** ‚Äì h·ªó tr·ª£ ng∆∞·ªùi d√πng theo phong c√°ch nh·∫π nh√†ng, g·∫ßn g≈©i, t·ª± nhi√™n nh∆∞ m·ªôt ng∆∞·ªùi b·∫°n th√¢n thi·ªán.\n\n"
        "üéØ M·ª•c ti√™u:\n"
        "1. Tr√≤ chuy·ªán ƒë·ªÉ thu th·∫≠p ƒë·ªß **16 th√¥ng tin s·ª©c kh·ªèe** d∆∞·ªõi ƒë√¢y (d√πng n·ªôi b·ªô ƒë·ªÉ ph√¢n t√≠ch).\n"
        "2. Khi ƒë·ªß, nh·∫Øc ng∆∞·ªùi d√πng g√µ **ph√¢n t√≠ch** ƒë·ªÉ tr·∫£ v·ªÅ k·∫øt qu·∫£ ML + t∆∞ v·∫•n chi ti·∫øt.\n\n"
        "üß† H∆∞·ªõng d·∫´n ph·∫£n h·ªìi:\n"
        "‚Ä¢ B·∫Øt ƒë·∫ßu b·∫±ng **m·ªôt l·ªùi ch√†o ·∫•m √°p, ch√¢n th√†nh** ‚Äì v√≠ d·ª•:\n"
        "  ‚ÄúCh√†o b·∫°n! üòä M√¨nh l√† b√°c sƒ© dinh d∆∞·ª°ng AI, h√¥m nay ƒë·ªìng h√†nh c√πng b·∫°n n√®!‚Äù\n\n"
        "‚Ä¢ **T·∫°o nh·ªãp k·∫øt n·ªëi c·∫£m x√∫c tr∆∞·ªõc khi h·ªèi s·ªë li·ªáu** ‚Äì v√≠ d·ª•:\n"
        "  ‚ÄúB·∫°n d·∫°o n√†y th·∫•y s·ª©c kh·ªèe ·ªïn kh√¥ng?‚Äù, ho·∫∑c ‚ÄúB·∫°n ƒëang c√≥ m·ª•c ti√™u g√¨ kh√¥ng ‚Äì tƒÉng c√¢n, gi·∫£m c√¢n hay ch·ªâ mu·ªën duy tr√¨ ha?‚Äù\n\n"
        "‚Ä¢ **Ch·ªâ khi ng∆∞·ªùi d√πng ph·∫£n h·ªìi t√≠ch c·ª±c ho·∫∑c s·∫µn s√†ng** ‚Üí m·ªõi xin ph√©p b·∫Øt ƒë·∫ßu h·ªèi: \n"
        "  ‚ÄúN·∫øu b·∫°n th·∫•y tho·∫£i m√°i, m√¨nh h·ªèi b·∫°n v√†i ƒëi·ªÅu nh·ªè ƒë·ªÉ h·ªó tr·ª£ t·ªët h∆°n nha.‚Äù\n\n"
        "‚Ä¢ Khi h·ªèi t·ª´ng m·ª•c:\n"
        "  ‚Äì D·∫´n d·∫Øt ng·∫Øn g·ªçn, t·ª± nhi√™n (kh√¥ng g·∫•p g√°p). V√≠ d·ª•:\n"
        "    ‚ÄúM√¨nh c√≥ th·ªÉ bi·∫øt tu·ªïi c·ªßa b·∫°n tr∆∞·ªõc ƒë∆∞·ª£c kh√¥ng n√®?‚Äù ho·∫∑c ‚ÄúB·∫°n cao t·∫ßm bao nhi√™u cm ha?‚Äù\n"
        "  ‚Äì Tuy·ªát ƒë·ªëi kh√¥ng h·ªèi 2‚Äì3 m·ª•c li·ªÅn nhau.\n"
        "  ‚Äì Gi·ªØa m·ªói l·∫ßn n√™n c√≥ nh·ªãp tr√≤ chuy·ªán: v√≠ d·ª• ‚ÄúOk, ƒë·ªÉ m√¨nh ghi l·∫°i nh√©.‚Äù ho·∫∑c ‚ÄúC·∫£m ∆°n b·∫°n ƒë√£ chia s·∫ª!‚Äù\n\n"
        "‚Ä¢ N·∫øu ng∆∞·ªùi d√πng tr·∫£ l·ªùi m∆° h·ªì ho·∫∑c sai ph·∫°m vi ‚ûú ƒëo√°n nh·∫π v√† x√°c nh·∫≠n l·∫°i:\n"
        "  _‚ÄúB·∫°n ƒë·ªãnh l√† kho·∫£ng 2 bu·ªïi t·∫≠p/tu·∫ßn ‚Äì ƒë√∫ng kh√¥ng?‚Äù_\n\n"
        "‚Ä¢ Khi nh·∫≠n th√¥ng tin r√µ r√†ng ‚ûú x√°c nh·∫≠n nh·∫π nh√†ng:\n"
        "  _‚ÄúM√¨nh ƒë√£ ghi CH2O = 2 l√≠t/ng√†y ‚Äì ƒë√∫ng kh√¥ng n√®?‚Äù_\n\n"
        "‚Ä¢ N·∫øu c√≤n thi·∫øu ‚ûú ch·ªçn t·ªëi ƒëa 1‚Äì2 m·ª•c ƒë·∫ßu danh s√°ch thi·∫øu ƒë·ªÉ h·ªèi ti·∫øp (∆∞u ti√™n Height, Weight n·∫øu tr·ªëng).\n\n"
        "‚Ä¢ Khi ƒë·ªß 16 m·ª•c ‚ûú nh·∫Øc ng∆∞·ªùi d√πng g√µ **ph√¢n t√≠ch** ƒë·ªÉ xem k·∫øt qu·∫£ v√† nh·∫≠n l·ªùi khuy√™n c√° nh√¢n h√≥a.\n\n"
        "‚ö†Ô∏è Kh√¥ng bao gi·ªù d√πng c·ª•m t·ª´ nh∆∞ 'tr∆∞·ªùng d·ªØ li·ªáu', 'form', 'm·∫´u th√¥ng tin'‚Ä¶\n"
        "‚ö†Ô∏è Kh√¥ng in ra danh s√°ch c√°c bi·∫øn s·ªë ‚Äì ch·ªâ d√πng n·ªôi b·ªô.\n"
        "‚ö†Ô∏è Gi·ªçng n√≥i ph·∫£i **g·ª£i c·∫£m gi√°c ƒëang ƒë∆∞·ª£c quan t√¢m**, ch·ª© kh√¥ng ph·∫£i ƒëang l√†m kh·∫£o s√°t.\n\n"
        "üìã D·ªØ li·ªáu c·∫ßn l·∫•y (16 m·ª•c n·ªôi b·ªô):\n"
        "- Age: Tu·ªïi (nƒÉm; >0)\n"
        "- Height: Chi·ªÅu cao (cm; >0)\n"
        "- Weight: C√¢n n·∫∑ng (kg; >0)\n"
        "- FCVC: ƒÇn rau (1=Kh√¥ng, 2=Th·ªânh tho·∫£ng, 3=Lu√¥n)\n"
        "- Gender: Male / Female\n"
        "- NCP: B·ªØa ch√≠nh/ng√†y (‚â•1)\n"
        "- TUE: Th·ªùi gian thi·∫øt b·ªã/ng√†y (‚â•0 gi·ªù)\n"
        "- FAF: Ng√†y t·∫≠p th·ªÉ d·ª•c/tu·∫ßn (0‚Äì7)\n"
        "- CH2O: L∆∞·ª£ng n∆∞·ªõc u·ªëng/ng√†y (l√≠t; >0)\n"
        "- CAEC: ƒÇn v·∫∑t (0‚Äì3)\n"
        "- CALC: R∆∞·ª£u bia (0‚Äì3)\n"
        "- family_history_with_overweight: Yes / No\n"
        "- MTRANS: Ph∆∞∆°ng ti·ªán di chuy·ªÉn (Walking, Bike, Motorbike, Public_Transportation, Car)\n"
        "- FAVC: Th√≠ch ƒë·ªì calo cao (Yes / No)\n"
        "- SCC: C√≥ ghi calo h√†ng ng√†y kh√¥ng? (Yes / No)\n"
        "- SMOKE: H√∫t thu·ªëc? (Yes / No)\n"
    )
}

session_messages = [SYSTEM_CORE]

# === 6. Bi·∫øn tr·∫°ng th√°i ch·ªù x√°c nh·∫≠n ===
# Khi ng∆∞·ªùi d√πng g√µ "ph√¢n t√≠ch" m√† ƒë·ªß 16 tr∆∞·ªùng, ta g·ª≠i summary r·ªìi set this flag = True.
# Khi next request l√† "x√°c nh·∫≠n", m·ªõi ch·∫°y predict.
awaiting_confirmation = False

# === 6b. Th√¥ng tin c·ªë ƒë·ªãnh cho t·ª´ng nh√£n ===
OBESITY_INFO = {
    "Insufficient_Weight": {
        "vi_name": "Thi·∫øu c√¢n",
        "bmi": "< 18.5",
        "risks": [
            "Suy gi·∫£m mi·ªÖn d·ªãch, d·ªÖ nhi·ªÖm b·ªánh",
            "Thi·∫øu vi ch·∫•t (s·∫Øt, k·∫Ωm, vitamin D)",
            "Gi·∫£m m·∫≠t ƒë·ªô x∆∞∆°ng, nguy c∆° lo√£ng x∆∞∆°ng"
        ],
        "goal": "TƒÉng 0.3‚Äì0.5 kg/tu·∫ßn b·∫±ng dinh d∆∞·ª°ng gi√†u ƒë·∫°m & t·∫≠p kh√°ng l·ª±c nh·∫π",
    },
    "Normal_Weight": {
        "vi_name": "C√¢n n·∫∑ng b√¨nh th∆∞·ªùng",
        "bmi": "18.5 ‚Äì 24.9",
        "risks": ["Ti·∫øp t·ª•c duy tr√¨ l·ªëi s·ªëng l√†nh m·∫°nh"],
        "goal": "Gi·ªØ BMI & v√≤ng eo t·ªëi ∆∞u; ‚â• 150 ph√∫t v·∫≠n ƒë·ªông/tu·∫ßn",
    },
    "Overweight_Level_I": {
        "vi_name": "Th·ª´a c√¢n m·ª©c I",
        "bmi": "25 ‚Äì 27.4",
        "risks": [
            "M·ª° m√°u, huy·∫øt √°p tƒÉng nh·∫π",
            "Ng∆∞ng th·ªü khi ng·ªß (nh·∫π)"
        ],
        "goal": "Gi·∫£m 5 % c√¢n n·∫∑ng (~0.5 kg/tu·∫ßn trong 3 th√°ng)",
    },
    "Overweight_Level_II": {
        "vi_name": "Th·ª´a c√¢n m·ª©c II",
        "bmi": "27.5 ‚Äì 29.9",
        "risks": ["Gan nhi·ªÖm m·ª° s·ªõm, ti·ªÅn ƒë√°i th√°o ƒë∆∞·ªùng"],
        "goal": "Gi·∫£m 7 % c√¢n n·∫∑ng; v√≤ng eo < 90 cm (nam) / 80 cm (n·ªØ)",
    },
    "Obesity_Type_I": {
        "vi_name": "B√©o ph√¨ lo·∫°i I",
        "bmi": "30 ‚Äì 34.9",
        "risks": [
            "Nguy c∆° b·ªánh tim m·∫°ch tƒÉng g·∫•p 2",
            "ƒêau kh·ªõp g·ªëi, th·∫Øt l∆∞ng"
        ],
        "goal": "Gi·∫£m 10 % c√¢n n·∫∑ng trong 6 th√°ng; theo d√µi huy·∫øt √°p 3 th√°ng/l·∫ßn",
    },
    "Obesity_Type_II": {
        "vi_name": "B√©o ph√¨ lo·∫°i II",
        "bmi": "35 ‚Äì 39.9",
        "risks": [
            "Ti·ªÉu ƒë∆∞·ªùng type 2, h·ªôi ch·ª©ng chuy·ªÉn h√≥a",
            "Ng∆∞ng th·ªü khi ng·ªß m·ª©c v·ª´a"
        ],
        "goal": "Gi·∫£m 10‚Äì15 % c√¢n n·∫∑ng; c√¢n nh·∫Øc thu·ªëc h·ªó tr·ª£",
    },
    "Obesity_Type_III": {
        "vi_name": "B√©o ph√¨ nghi√™m tr·ªçng",
        "bmi": "‚â• 40",
        "risks": [
            "Nguy c∆° t·ª≠ vong do tim m·∫°ch tƒÉng cao",
            "Tho√°i h√≥a kh·ªõp n·∫∑ng, tr·∫ßm c·∫£m"
        ],
        "goal": "Gi·∫£m ‚â• 15 % c√¢n n·∫∑ng; xem x√©t ph·∫´u thu·∫≠t gi·∫£m c√¢n",
    },
}


# === 7. H√†m d·ª± ƒëo√°n (predict_obesity) ===
def predict_obesity(input_data: dict) -> str:
    """
    Nh·∫≠n dict 16 tr∆∞·ªùng, √©p ki·ªÉu chu·∫©n,
    encode 6 c·ªôt ch·ªØ, sau ƒë√≥ d·ª± ƒëo√°n.
    """
    df = pd.DataFrame([input_data])

    # 6 c·ªôt ch·ªØ ‚Üí d√πng LabelEncoder (x·ª≠ l√Ω gi√° tr·ªã l·∫° an to√†n)
    for col in NEED_ENCODE:
        if col in df.columns:
            enc = label_encoders[col]
            # N·∫øu gi√° tr·ªã ch∆∞a n·∫±m trong enc.classes_, g√°n v·ªÅ class_0 ƒë·ªÉ tr√°nh ValueError
            df[col] = df[col].apply(
                lambda x: x if x in enc.classes_ else enc.classes_[0]
            )
            df[col] = enc.transform(df[col])

    # C√°c c·ªôt s·ªë ‚Üí √©p ki·ªÉu int/float
    for col in NUMERIC_COLS:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    # Gi·ªØ ƒë√∫ng th·ª© t·ª± selected_features
    df = df[selected_features]

    return model.predict(df)[0]

# === 8. Sinh g√≥i t∆∞ v·∫•n chi ti·∫øt ===
def generate_advice(label: str) -> str:
    """
    T·∫°o l·ªùi khuy√™n g·ªìm: √Ω nghƒ©a m·ª©c ƒë·ªô, nguy c∆°, m·ª•c ti√™u,
    3 th√≥i quen, th·ª±c ƒë∆°n 1 ng√†y, l·ªãch t·∫≠p 7 ng√†y, c√°ch theo d√µi.
    """
    info = OBESITY_INFO.get(label, {})
    vi_name  = info.get("vi_name", label)
    bmi_txt  = info.get("bmi", "‚Äî")
    risks_md = "\n".join(f"‚Ä¢ {r}" for r in info.get("risks", []))
    goal_txt = info.get("goal", "Duy tr√¨ l·ªëi s·ªëng l√†nh m·∫°nh")

    user_prompt = dedent(f"""
        B·∫°n ƒëang ·ªü nh√≥m **{vi_name}** (BMI {bmi_txt}).
        Nguy c∆° s·ª©c kh·ªèe ch√≠nh:
        {risks_md}

        üéØ **M·ª•c ti√™u**: {goal_txt}

        H√£y cho t√¥i:
        1. Gi·∫£i th√≠ch ng·∫Øn g·ªçn v√¨ sao t√¥i ·ªü nh√≥m n√†y.
        2. 3 th√≥i quen c·∫ßn √°p d·ª•ng ngay (ƒë√°nh s·ªë ‚ë†‚ë°‚ë¢).
        3. Th·ª±c ƒë∆°n g·ª£i √Ω 1 ng√†y (3 b·ªØa ch√≠nh + 2 ph·ª•) k√®m kcal.
        4. L·ªãch t·∫≠p 7 ng√†y m·ª©c ƒë·ªô v·ª´a (ghi r√µ ph√∫t & c∆∞·ªùng ƒë·ªô).
        5. C√°ch t·ª± theo d√µi ti·∫øn tr√¨nh & m·ªëc t√°i kh√°m.

        Tr√¨nh b√†y th√¢n thi·ªán, xen emoji ph√π h·ª£p, s√∫c t√≠ch, d·ªÖ th·ª±c thi.
    """)

    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system",
             "content": "B·∫°n l√† chuy√™n gia dinh d∆∞·ª°ng & hu·∫•n luy·ªán s·ª©c kh·ªèe, ∆∞u ti√™n l·ªùi khuy√™n th·ª±c ti·ªÖn ng·∫Øn g·ªçn."},
            {"role": "user", "content": user_prompt},
        ],
        temperature=0.7,
    )
    return resp.choices[0].message.content.strip()


# === 9. Tr√≠ch dict 16 tr∆∞·ªùng t·ª´ l·ªãch s·ª≠ ===
def extract_model_input_from_history() -> dict:
    prompt = {
        "role": "user",
        "content": (
            "D·ª±a tr√™n to√†n b·ªô cu·ªôc h·ªôi tho·∫°i d∆∞·ªõi ƒë√¢y gi·ªØa b·∫°n v√† ng∆∞·ªùi d√πng, "
            "h√£y tr·∫£ v·ªÅ m·ªôt dict Python ch·ªâ g·ªìm nh·ªØng kh√≥a sau:\n\n"
            f"{', '.join(required_fields)}\n\n"
            "Gi√° tr·ªã ph·∫£i ƒë√∫ng ki·ªÉu:\n"
            "- C√°c tr∆∞·ªùng s·ªë ‚Üí int ho·∫∑c float\n"
            "- Gender ‚Üí 'Male' ho·∫∑c 'Female'\n"
            "- Yes/No ‚Üí 'Yes' ho·∫∑c 'No'\n"
            "- MTRANS ‚Üí ƒë√∫ng m·ªôt trong: Walking, Bike, Motorbike, Public_Transportation, Car\n\n"
            "‚ö†Ô∏è Ch·ªâ tr·∫£ v·ªÅ `dict Python`, kh√¥ng ch√∫ th√≠ch, kh√¥ng l·ªùi gi·∫£i th√≠ch. V√≠ d·ª•:\n"
            "{'Gender': 'Male', 'Age': 22, 'Height': 170, ...}\n\n"
            "‚ö†Ô∏è N·∫øu thi·∫øu tr∆∞·ªùng n√†o, h√£y **b·ªè lu√¥n kh√≥a ƒë√≥** trong dict.\n"
            "B·∫Øt ƒë·∫ßu tr·∫£ k·∫øt qu·∫£ ·ªü d√≤ng sau:"
        )
    }

    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=session_messages + [prompt],
        temperature=0,
    )

    try:
        return ast.literal_eval(resp.choices[0].message.content.strip())
    except Exception as e:
        print("‚ö†Ô∏è L·ªói parse:", e)
        return {}


# === 10. Prompt ·∫©n ƒë·ªông theo t·ª´ng l∆∞·ª£t (SYSTEM-FLOW) ===
def build_flow_prompt(current: dict, missing: list[str]) -> dict:
    row = [str(current.get(col, "")) for col in required_fields]
    table = "\t".join(required_fields) + "\n" + "\t".join(row)

    definitions = (
        "üìã ƒê·ªãnh nghƒ©a (n·ªôi b·ªô, kh√¥ng hi·ªán ra ngo√†i):\n"
        "- Age: s·ªë nguy√™n > 0\n"
        "- FCVC: 1‚Äì3 (m·ª©c ƒë·ªô ƒÉn rau)\n"
        "- Gender: Male/Female\n"
        "- NCP: ‚â•1\n"
        "- TUE: ‚â•0\n"
        "- FAF: 0‚Äì7\n"
        "- CH2O: >0\n"
        "- CAEC, CALC: 0‚Äì3\n"
        "- family_history_with_overweight, FAVC, SCC, SMOKE: Yes/No\n"
        "- MTRANS: Walking/Bike/Motorbike/Public_Transportation/Car"
    )

    instructions = (
        "üéØ H∆∞·ªõng d·∫´n x·ª≠ l√Ω:\n"
        "‚Ä¢ N·∫øu `MISSING` r·ªóng ‚Üí nh·∫Øc ng∆∞·ªùi d√πng g√µ **ph√¢n t√≠ch**, kh√¥ng h·ªèi g√¨ th√™m.\n"
        "‚Ä¢ N·∫øu c√≤n thi·∫øu ‚Üí h·ªèi t·ªëi ƒëa 1‚Äì2 tr∆∞·ªùng ƒë·∫ßu (∆∞u ti√™n Height, Weight n·∫øu ch∆∞a c√≥).\n"
        "‚Ä¢ Khi nh·∫≠n gi√° tr·ªã, x√°c nh·∫≠n: _‚ÄúM√¨nh ƒë√£ ghi FAF = 3 ng√†y/tu·∫ßn ‚Äì ƒë√∫ng kh√¥ng?‚Äù_\n"
        "‚Ä¢ N·∫øu gi√° tr·ªã m∆° h·ªì ‚Üí h·ªèi l·∫°i nh·∫π nh√†ng k√®m v√≠ d·ª•.\n"
        "‚Ä¢ Gi·ªØ ng√¥n ng·ªØ t·ª± nhi√™n, nh∆∞ m·ªôt b√°c sƒ© t∆∞ v·∫•n nh·∫π nh√†ng."
    )

    # üëâ  Tr·∫£ v·ªÅ v·ªõi role = 'assistant' ƒë·ªÉ KH√îNG ƒë√® system-prompt ch√≠nh
    return {
        "role": "assistant",
        "content": (
            f"### SYSTEM FLOW (·∫®N) ###\n"
            f"{definitions}\n\n"
            f"DATA:\n{table}\n\n"
            f"MISSING: {missing}\n\n"
            f"{instructions}"
        )
    }


# === 11. H√†m chat ch√≠nh ===
def chat_with_gpt(user_input: str) -> str:
    # L∆∞u l·ªùi user & log
    session_messages.append({"role": "user", "content": user_input})
    write_log(f"USER: {user_input}")

    # Ph√¢n t√≠ch tr·∫°ng th√°i hi·ªán t·∫°i
    current = extract_model_input_from_history()
    missing = [f for f in required_fields if f not in current or current[f] in ["", None]]
    flow_prompt = build_flow_prompt(current, missing)  # role = assistant

    messages = [SYSTEM_CORE] + session_messages[1:] + [flow_prompt]

    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.5,
    )

    reply = resp.choices[0].message.content.strip()
    session_messages.append({"role": "assistant", "content": reply})
    write_log(f"ASSISTANT: {reply}")        # üìù log assistant

    return reply


# === 12. Flask routes ===
@app.route("/chat")
@app.route("/")
def chat_ui():
    global session_messages, awaiting_confirmation

    # üîÑ RESET phi√™n m·ªói l·∫ßn t·∫£i trang
    session_messages = [SYSTEM_CORE]
    awaiting_confirmation = False

    # üìÇ t·∫°o file log m·ªõi cho phi√™n n√†y
    app.log_name = f"chat_{uuid.uuid4().hex[:8]}.txt"
    write_log("=== NEW SESSION ===")

    return render_template("chatgpt_ui.html")


# === 12. Flask routes ===
@app.route("/ask", methods=["POST"])
def ask():
    global session_messages, awaiting_confirmation

    user_input = request.json.get("message", "").strip()
    write_log(f"USER: {user_input}")        # üìù log ph√°t ng√¥n ng∆∞·ªùi d√πng

    # 1Ô∏è‚É£  ƒêANG CH·ªú X√ÅC NH·∫¨N
    if awaiting_confirmation and user_input.lower() in ["x√°c nh·∫≠n", "xac nhan", "confirm"]:
        user_data = extract_model_input_from_history()
        write_log(f"MODEL_INPUT: {user_data}")   # log dict g·ª≠i v√†o RF

        label = predict_obesity(user_data)
        write_log(f"PREDICTED_LABEL: {label}")   # log nh√£n d·ª± ƒëo√°n

        advice = generate_advice(label)
        final_msg = f"üìä **K·∫øt qu·∫£**\n\nB·∫°n thu·ªôc nh√≥m **{label}**.\n\n{advice}"
        session_messages.append({"role": "assistant", "content": final_msg})
        write_log(f"ASSISTANT: {final_msg}")     # log ph·∫£n h·ªìi bot

        awaiting_confirmation = False            # reset c·ªù
        return jsonify({"reply": final_msg})

    # 2Ô∏è‚É£  NG∆Ø·ªúI D√ôNG G√ï ‚ÄúPH√ÇN T√çCH‚Äù
    if user_input.lower() in ["ph√¢n t√≠ch", "phan tich", "pt", "ti·∫øp t·ª•c"]:
        user_data = extract_model_input_from_history()
        missing = [f for f in required_fields if f not in user_data or user_data[f] in ["", None]]

        # 2.1  Thi·∫øu th√¥ng tin
        if missing:
            reply = f"‚ö†Ô∏è M√¨nh c√≤n thi·∫øu: {', '.join(missing)}. B·∫°n b·ªï sung nh√©!"
            session_messages.append({"role": "assistant", "content": reply})
            write_log(f"ASSISTANT: {reply}")     # log ph·∫£n h·ªìi bot
            return jsonify({"reply": reply})

        # 2.2  ƒê√£ ƒë·ªß 16 tr∆∞·ªùng ‚Äì t·∫°o t√≥m t·∫Øt
        nice_map = {
            "Gender": "Gi·ªõi t√≠nh", "Age": "Tu·ªïi", "Height": "Chi·ªÅu cao", "Weight": "C√¢n n·∫∑ng",
            "family_history_with_overweight": "Ti·ªÅn s·ª≠ th·ª´a c√¢n gia ƒë√¨nh",
            "FAVC": "Th√≠ch ƒë·ªì calo cao", "FCVC": "M·ª©c ƒë·ªô ƒÉn rau (1-3)",
            "NCP": "B·ªØa ch√≠nh/ng√†y", "CAEC": "M·ª©c ƒë·ªô ƒÉn v·∫∑t (0-3)",
            "SMOKE": "H√∫t thu·ªëc", "CH2O": "L∆∞·ª£ng n∆∞·ªõc (l√≠t/ng√†y)",
            "SCC": "Ghi ch√©p calo", "FAF": "Ng√†y t·∫≠p/tu·∫ßn",
            "TUE": "Gi·ªù d√πng thi·∫øt b·ªã/ng√†y", "CALC": "M·ª©c ƒë·ªô u·ªëng r∆∞·ª£u/bia (0-3)",
            "MTRANS": "Ph∆∞∆°ng ti·ªán di chuy·ªÉn"
        }
        summary_lines = []
        for key in required_fields:
            val = user_data.get(key)
            if isinstance(val, str) and val.lower() in ["yes", "no"]:
                val = "C√≥" if val.lower() == "yes" else "Kh√¥ng"
            summary_lines.append(f"- {nice_map.get(key, key)}: {val}")

        summary = (
            "üìù **T√≥m t·∫Øt th√¥ng tin b·∫°n ƒë√£ cung c·∫•p:**\n" +
            "\n".join(summary_lines) +
            "\n\nN·∫øu b·∫°n mu·ªën ƒëi·ªÅu ch·ªânh b·∫•t k·ª≥ th√¥ng tin n√†o, vui l√≤ng nh·∫≠p l·∫°i gi√° tr·ªã t∆∞∆°ng ·ª©ng.\n"
            "N·∫øu m·ªçi th·ª© ƒë√£ ƒë√∫ng, b·∫°n g√µ **x√°c nh·∫≠n** ƒë·ªÉ m√¨nh ti·∫øn h√†nh ph√¢n t√≠ch nh√©!"
        )

        awaiting_confirmation = True
        session_messages.append({"role": "assistant", "content": summary})
        write_log(f"ASSISTANT: {summary}")       # log ph·∫£n h·ªìi bot
        return jsonify({"reply": summary})

    # 3Ô∏è‚É£  TR∆Ø·ªúNG H·ª¢P B√åNH TH∆Ø·ªúNG ‚Äì ti·∫øp t·ª•c h·ªôi tho·∫°i
    reply = chat_with_gpt(user_input)            # chat_with_gpt ƒë√£ t·ª± log ASSISTANT
    return jsonify({"reply": reply})


# === 13. Ch·∫°y app ===
if __name__ == "__main__":
    app.run(debug=True)


from werkzeug.middleware.proxy_fix import ProxyFix
app.wsgi_app = ProxyFix(app.wsgi_app)

def handler(request, response):
    return app(request.environ, response)
